{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4df863d",
   "metadata": {},
   "source": [
    "### Вебинар 6. Двухуровневые модели рекомендаций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e8af318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Для работы с матрицами\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Для категориальных переменных\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Матричная факторизация\n",
    "from implicit import als\n",
    "\n",
    "# Модель второго уровня\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join(os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Написанные нами функции\n",
    "from metrics import precision_at_k, recall_at_k\n",
    "from utils import prefilter_items\n",
    "from recommenders import MainRecommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aad222cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>basket_id</th>\n",
       "      <th>day</th>\n",
       "      <th>item_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>sales_value</th>\n",
       "      <th>store_id</th>\n",
       "      <th>retail_disc</th>\n",
       "      <th>trans_time</th>\n",
       "      <th>week_no</th>\n",
       "      <th>coupon_disc</th>\n",
       "      <th>coupon_match_disc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1004906</td>\n",
       "      <td>1</td>\n",
       "      <td>1.39</td>\n",
       "      <td>364</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1033142</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id    basket_id  day  item_id  quantity  sales_value  store_id  \\\n",
       "0     2375  26984851472    1  1004906         1         1.39       364   \n",
       "1     2375  26984851472    1  1033142         1         0.82       364   \n",
       "\n",
       "   retail_disc  trans_time  week_no  coupon_disc  coupon_match_disc  \n",
       "0         -0.6        1631        1          0.0                0.0  \n",
       "1          0.0        1631        1          0.0                0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('retail_train.csv')\n",
    "item_features = pd.read_csv('product.csv')\n",
    "user_features = pd.read_csv('hh_demographic.csv')\n",
    "\n",
    "# column processing\n",
    "item_features.columns = [col.lower() for col in item_features.columns]\n",
    "user_features.columns = [col.lower() for col in user_features.columns]\n",
    "\n",
    "item_features.rename(columns={'product_id': 'item_id'}, inplace=True)\n",
    "user_features.rename(columns={'household_key': 'user_id'}, inplace=True)\n",
    "\n",
    "\n",
    "# Важна схема обучения и валидации!\n",
    "# -- давние покупки -- | -- 6 недель -- | -- 3 недель -- \n",
    "# подобрать размер 2-ого датасета (6 недель) --> learning curve (зависимость метрики recall@k от размера датасета)\n",
    "val_lvl_1_size_weeks = 6\n",
    "val_lvl_2_size_weeks = 3\n",
    "\n",
    "data_train_lvl_1 = data[data['week_no'] < data['week_no'].max() - (val_lvl_1_size_weeks + val_lvl_2_size_weeks)]\n",
    "data_val_lvl_1 = data[(data['week_no'] >= data['week_no'].max() - (val_lvl_1_size_weeks + val_lvl_2_size_weeks)) &\n",
    "                      (data['week_no'] < data['week_no'].max() - (val_lvl_2_size_weeks))]\n",
    "\n",
    "data_train_lvl_2 = data_val_lvl_1.copy()  # Для наглядности. Далее мы добавим изменения, и они будут отличаться\n",
    "data_val_lvl_2 = data[data['week_no'] >= data['week_no'].max() - val_lvl_2_size_weeks]\n",
    "\n",
    "data_train_lvl_1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912a6d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_items_before = data_train_lvl_1['item_id'].nunique()\n",
    "\n",
    "data_train_lvl_1 = prefilter_items(data_train_lvl_1, take_n_popular=5000)\n",
    "\n",
    "n_items_after = data_train_lvl_1['item_id'].nunique()\n",
    "print('Decreased # items from {} to {}'.format(n_items_before, n_items_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6386db",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender = MainRecommender(data_train_lvl_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b739a4",
   "metadata": {},
   "source": [
    "Задание 1.\n",
    "A) Попробуйте различные варианты генерации кандидатов. Какие из них дают наибольший recall@k ?\n",
    "\n",
    "Пока пробуем отобрать 50 кандидатов (k=50)\n",
    "\n",
    "Качество измеряем на data_val_matcher: следующие 6 недель после трейна\n",
    "\n",
    "Дают ли own recommendtions + top-popular лучший recall?\n",
    "\n",
    "B)* Как зависит recall@k от k? Постройте для одной схемы генерации кандидатов эту зависимость для k = {20, 50, 100, 200, 500}\n",
    "\n",
    "C)* Исходя из прошлого вопроса, как вы думаете, какое значение k является наиболее разумным?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16208fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lvl_1 = data_val_lvl_1.groupby('user_id')['item_id'].unique().reset_index()\n",
    "result_lvl_1.columns=['user_id', 'actual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69980c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lvl_1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ddc70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lvl_1['user_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e5f40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lvl_1['als_rec_50'] = result_lvl_1['user_id'].apply(lambda x: recommender.get_als_recommendations(x, N=50))\n",
    "result_lvl_1['own_rec_50'] = result_lvl_1['user_id'].apply(lambda x: recommender.get_own_recommendations(x, N=50))\n",
    "result_lvl_1['sim_items_rec_50'] = result_lvl_1['user_id'].apply(lambda x: recommender.get_similar_items_recommendation(x, N=50))\n",
    "result_lvl_1['sim_user_rec_50'] = result_lvl_1['user_id'].apply(lambda x: recommender.get_similar_users_recommendation(x, N=50))\n",
    "\n",
    "result_lvl_1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf491e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_total = pd.DataFrame()\n",
    "recall_total['user_id'] = result_lvl_1['user_id']\n",
    "recall_total['als_rec_50'] = result_lvl_1.apply(lambda x: recall_at_k(x['als_rec_50'], x['actual'], 50), axis=1)\n",
    "recall_total['own_rec_50'] = result_lvl_1.apply(lambda x: recall_at_k(x['own_rec_50'], x['actual'], 50), axis=1)\n",
    "recall_total['sim_items_rec_50'] = result_lvl_1.apply(lambda x: recall_at_k(x['sim_items_rec_50'], x['actual'], 50), axis=1)\n",
    "recall_total['sim_user_rec_50'] = result_lvl_1.apply(lambda x: recall_at_k(x['sim_user_rec_50'], x['actual'], 50), axis=1)\n",
    "\n",
    "recall_total['als_rec_50'].mean(), recall_total['own_rec_50'].mean(), recall_total['sim_items_rec_50'].mean(), recall_total['sim_user_rec_50'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12984881",
   "metadata": {},
   "source": [
    "### Дают ли own recommendtions + top-popular лучший recall?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07eac63e",
   "metadata": {},
   "source": [
    "Да, лучший recall у recommendtions + top-popular (0,139)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9bba8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lvl_1['own_rec_20'] = result_lvl_1['user_id'].apply(lambda x: recommender.get_own_recommendations(x, N=20))\n",
    "result_lvl_1['own_rec_50'] = result_lvl_1['user_id'].apply(lambda x: recommender.get_own_recommendations(x, N=50))\n",
    "result_lvl_1['own_rec_100'] = result_lvl_1['user_id'].apply(lambda x: recommender.get_own_recommendations(x, N=100))\n",
    "result_lvl_1['own_rec_500'] = result_lvl_1['user_id'].apply(lambda x: recommender.get_own_recommendations(x, N=500))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eb59b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_total['own_rec_20'] = result_lvl_1.apply(lambda x: recall_at_k(x['own_rec_20'], x['actual'], 20), axis=1)\n",
    "recall_total['own_rec_50'] = result_lvl_1.apply(lambda x: recall_at_k(x['own_rec_50'], x['actual'], 50), axis=1)\n",
    "recall_total['own_rec_100'] = result_lvl_1.apply(lambda x: recall_at_k(x['own_rec_100'], x['actual'], 100), axis=1)\n",
    "recall_total['own_rec_500'] = result_lvl_1.apply(lambda x: recall_at_k(x['own_rec_500'], x['actual'], 500), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6a3414",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_total['own_rec_20'].mean(), recall_total['own_rec_50'].mean(), recall_total['own_rec_100'].mean(), recall_total['own_rec_200'].mean(), recall_total['own_rec_500'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cb8842",
   "metadata": {},
   "source": [
    "B)* Как зависит recall@k от k? Постройте для одной схемы генерации кандидатов эту зависимость для k = {20, 50, 100, 200, 500}\n",
    "\n",
    "C)* Исходя из прошлого вопроса, как вы думаете, какое значение k является наиболее разумным?\n",
    "\n",
    "Чем, больше k, тем выше recall, но разумнее наверное брать наименьшее (k=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea09169d",
   "metadata": {},
   "source": [
    "### Задание 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683227fb",
   "metadata": {},
   "source": [
    "Обучите модель 2-ого уровня, при этом:\n",
    "\n",
    "- Добавьте минимум по 2 фичи для юзера, товара и пары юзер-товар\n",
    "- Измерьте отдельно precision@5 модели 1-ого уровня и двухуровневой модели на data_val_lvl_2\n",
    "- Вырос ли precision@5 при использовании двухуровневой модели?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4768fb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_lvl_2 = pd.DataFrame(data_train_lvl_2['user_id'].unique())\n",
    "users_lvl_2.columns = ['user_id']\n",
    "users_lvl_2['candidates'] = users_lvl_2['user_id'].apply(lambda x: recommender.get_own_recommendations(x, N=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c1e915",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = users_lvl_2.apply(lambda x: pd.Series(x['candidates']), axis=1).stack().reset_index(level=1, drop=True)\n",
    "s.name = 'item_id'\n",
    "users_lvl_2 = users_lvl_2.drop('candidates', axis=1).join(s)\n",
    "users_lvl_2['drop'] = 1\n",
    "\n",
    "users_lvl_2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dee7367",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_lvl_2 = data_train_lvl_2[['user_id', 'item_id']].copy()\n",
    "targets_lvl_2['target'] = 1  # тут только покупки \n",
    "\n",
    "targets_lvl_2 = users_lvl_2.merge(targets_lvl_2, on=['user_id', 'item_id'], how='left')\n",
    "\n",
    "targets_lvl_2['target'].fillna(0, inplace= True)\n",
    "\n",
    "targets_lvl_2.drop_duplicates(subset =['user_id', 'item_id'], keep = 'first', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62e23c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_lvl_2 = data_train_lvl_2.merge(item_features, on='item_id', how='left')\n",
    "data_train_lvl_2 = data_train_lvl_2.merge(user_features, on='user_id', how='left')\n",
    "\n",
    "data_train_lvl_2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ded0f51",
   "metadata": {},
   "source": [
    "### Генерация фичей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7d8f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Количество покупок по категориям\n",
    "def create_feature_u_1(df=data_train_lvl_2):\n",
    "    feat_u_1 = df[['user_id', 'department']].copy()\n",
    "    feat_u_1 = pd.get_dummies(feat_u_1)\n",
    "    feat_u_1 = feat_u_1.groupby(by='user_id').sum()\n",
    "\n",
    "    return feat_u_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ed4c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Средний чек\n",
    "def create_feature_u_2(df=data_train_lvl_2):\n",
    "    feat_u_2 = df[['user_id', 'basket_id', 'sales_value']].copy()\n",
    "    feat_u_2 = feat_u_2.groupby(by=['user_id', 'basket_id']).sum()\n",
    "    feat_u_2 = feat_u_2.groupby(by=['user_id']).mean()\n",
    "    feat_u_2.rename(columns={\"sales_value\": \"average_bill\"}, inplace=True)\n",
    "\n",
    "    return feat_u_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881c0cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кол-во покупок в неделю\n",
    "def create_feature_i_1(df=data_train_lvl_2):\n",
    "    feat_i_1 = df[['item_id', 'quantity', 'week_no']].copy()\n",
    "    feat_i_1 = feat_i_1[feat_i_1['quantity'] > 0]\n",
    "    feat_i_1 = feat_i_1.groupby(by=['item_id', 'week_no']).sum()\n",
    "    feat_i_1 = feat_i_1.groupby(by=['item_id']).mean()\n",
    "    feat_i_1.rename(columns={\"quantity\": \"quantity_per_week\"}, inplace=True)\n",
    "\n",
    "    return feat_i_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710cb63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Средняя цена товара в категории\n",
    "def create_feature_i_2(df=data_train_lvl_2):\n",
    "    feat_i_2 = df[['item_id', 'quantity', 'sales_value', 'sub_commodity_desc']].copy()\n",
    "    feat_i_2 = feat_i_2[feat_i_2['quantity'] > 0]\n",
    "    feat_i_2['per_unit'] = feat_i_2['sales_value'] / feat_i_2['quantity']\n",
    "    avr_per_comm = feat_i_2.groupby(by=['sub_commodity_desc']).mean()[['per_unit']].rename(columns={\"per_unit\": \"avr_per_comm\"})\n",
    "    \n",
    "    return avr_per_comm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe0e6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Средняя сумма покупки 1 товара в каждой категории (берем категорию item_id)) - (Цена item_id)\n",
    "def create_feature_u_i_1(avr_per_comm, df=data_train_lvl_2):\n",
    "    feat_u_i_1 = df[['user_id', 'item_id', 'quantity', 'sales_value', 'sub_commodity_desc']].copy()\n",
    "    feat_u_i_1 = feat_u_i_1[feat_u_i_1['quantity'] > 0]\n",
    "    feat_u_i_1 = feat_u_i_1.merge(avr_per_comm, on=['sub_commodity_desc'], how='left')  # avr_per_comm посчитан выше в feat_i_2\n",
    "    feat_u_i_1['per_unit'] = feat_u_i_1['sales_value'] / feat_u_i_1['quantity']\n",
    "    feat_u_i_1['diff_unit_avr'] = feat_u_i_1['per_unit'] - feat_u_i_1['avr_per_comm']\n",
    "    feat_u_i_1 = feat_u_i_1[['user_id', 'item_id', 'diff_unit_avr']]\n",
    "\n",
    "    return feat_u_i_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76573bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Кол-во покупок юзером конкретной категории в неделю) / (Среднее кол-во покупок всеми юзерами конкретной категории в неделю)\n",
    "def create_feature_u_i_2(df=data_train_lvl_2):\n",
    "    feat_u_i_2 = df[['user_id', 'quantity', 'sub_commodity_desc', 'week_no']].copy()\n",
    "    feat_u_i_2 = feat_u_i_2[feat_u_i_2['quantity'] > 0]\n",
    "    total_u = feat_u_i_2.groupby(by=['sub_commodity_desc', 'week_no']).sum()[['quantity']].rename(columns={\"quantity\": \"quantity_per_week\"})\n",
    "    feat_u_i_2 = feat_u_i_2.groupby(by=['user_id', 'sub_commodity_desc', 'week_no'], as_index = False).sum()\n",
    "    feat_u_i_2 = feat_u_i_2.merge(total_u, on=['sub_commodity_desc', 'week_no'], how='left')\n",
    "    feat_u_i_2 = feat_u_i_2.groupby(by=['user_id', 'sub_commodity_desc'], as_index = False).mean()\n",
    "    feat_u_i_2['diff_2'] = feat_u_i_2['quantity'] / feat_u_i_2['quantity_per_week']\n",
    "    feat_u_i_2 = feat_u_i_2[['user_id', 'sub_commodity_desc', 'diff_2']]\n",
    "    \n",
    "    return feat_u_i_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d660e90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сводная таблица\n",
    "feat_u_1 = create_feature_u_1(df=data_train_lvl_2)\n",
    "feat_u_2 = create_feature_u_2(df=data_train_lvl_2)\n",
    "feat_i_1 = create_feature_i_1(df=data_train_lvl_2)\n",
    "avr_per_comm = create_feature_i_2(df=data_train_lvl_2)\n",
    "feat_u_i_1 = create_feature_u_i_1(avr_per_comm=avr_per_comm, df=data_train_lvl_2)\n",
    "feat_u_i_2 = create_feature_u_i_2(df=data_train_lvl_2)\n",
    "\n",
    "\n",
    "result = targets_lvl_2.merge(item_features[['item_id', 'sub_commodity_desc']], on=['item_id'], how='left')\n",
    "\n",
    "result = result.merge(feat_u_1, on=['user_id'], how='left')\n",
    "result = result.merge(feat_u_2, on=['user_id'], how='left')\n",
    "\n",
    "result = result.merge(feat_i_1, on=['item_id'], how='left')\n",
    "result = result.merge(avr_per_comm, on=['sub_commodity_desc'], how='left')\n",
    "\n",
    "result = result.merge(feat_u_i_1, on=['user_id', 'item_id'], how='left')\n",
    "result = result.merge(feat_u_i_2, on=['user_id', 'sub_commodity_desc'], how='left')\n",
    "\n",
    "result.fillna(value=0, inplace=True)\n",
    "result.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abf8394",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "result[\"sub_commodity_desc\"] = le.fit_transform(result[\"sub_commodity_desc\"])\n",
    "\n",
    "result.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e49cc6",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e309cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = result.drop('target', axis=1)\n",
    "y_train = result[['target']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c720a17d",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e896284",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_val = pd.DataFrame(data_val_lvl_2['user_id'].unique())\n",
    "users_val.columns = ['user_id']\n",
    "users_val['candidates'] = users_val['user_id'].apply(lambda x: recommender.get_own_recommendations(x, N=200))\n",
    "\n",
    "s = users_val.apply(lambda x: pd.Series(x['candidates']), axis=1).stack().reset_index(level=1, drop=True)\n",
    "s.name = 'item_id'\n",
    "users_val = users_val.drop('candidates', axis=1).join(s)\n",
    "users_val['drop'] = 1\n",
    "\n",
    "targets_val = data_val_lvl_2[['user_id', 'item_id']].copy()\n",
    "targets_val['target'] = 1  # тут только покупки \n",
    "targets_val = users_val.merge(targets_val, on=['user_id', 'item_id'], how='left')\n",
    "\n",
    "targets_val['target'].fillna(0, inplace= True)\n",
    "targets_val.drop_duplicates(subset =['user_id', 'item_id'], keep = 'first', inplace = True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430fdee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем фичи\n",
    "\n",
    "result_val = targets_val.merge(item_features[['item_id', 'sub_commodity_desc']], on=['item_id'], how='left')\n",
    "\n",
    "result_val = result_val.merge(feat_u_1, on=['user_id'], how='left')\n",
    "result_val = result_val.merge(feat_u_2, on=['user_id'], how='left')\n",
    "\n",
    "result_val = result_val.merge(feat_i_1, on=['item_id'], how='left')\n",
    "result_val = result_val.merge(avr_per_comm, on=['sub_commodity_desc'], how='left')\n",
    "\n",
    "result_val = result_val.merge(feat_u_i_1, on=['user_id', 'item_id'], how='left')\n",
    "result_val = result_val.merge(feat_u_i_2, on=['user_id', 'sub_commodity_desc'], how='left')\n",
    "\n",
    "result_val.fillna(value=0, inplace=True)\n",
    "result_val.drop_duplicates(subset =['user_id', 'item_id'], keep = 'first', inplace = True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c12e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_val[\"sub_commodity_desc\"] = le.transform(result_val[\"sub_commodity_desc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c7c25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_val = result_val.reindex(columns = result.columns, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a5b709",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = result_val.drop('target', axis=1)\n",
    "y_val = result_val[['target']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5cb368",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427b4072",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lgb = LGBMClassifier(objective='binary', max_depth=7)\n",
    "lgb.fit(X_train, y_train)\n",
    "\n",
    "val_preds = lgb.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c26a51",
   "metadata": {},
   "source": [
    "### Берем топ 5 для каждого юзера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d905f2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5 = targets_val.copy()\n",
    "top_5['score'] = [x[1] for x in val_preds]\n",
    "top_5 = top_5.sort_values(['user_id', 'score'], ascending=False).groupby('user_id').head(5)\n",
    "top_5.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfc1852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision_at_5\n",
    "top_5['target'].sum() / top_5.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bc058c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision_at_5 у get_own_recommender\n",
    "top_5_get_own = targets_val.groupby('user_id').head(5)\n",
    "top_5_get_own['target'].sum() / top_5_get_own.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5938fef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# тоже precision_at_5 у get_own_recommender для проверки\n",
    "result_lvl_2 = data_val_lvl_2.groupby('user_id')['item_id'].unique().reset_index()\n",
    "result_lvl_2.columns=['user_id', 'actual']\n",
    "result_lvl_2['own_rec_5'] = result_lvl_2['user_id'].apply(lambda x: recommender.get_own_recommendations(x, N=5))\n",
    "\n",
    "result_lvl_2.apply(lambda x: precision_at_k(x['own_rec_5'], x['actual'], 5), axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df9c049",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
